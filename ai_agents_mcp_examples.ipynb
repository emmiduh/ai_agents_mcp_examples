{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZhCGBv45sJF0P6STlZ+og",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmiduh/ai_agents_mcp_examples/blob/main/ai_agents_mcp_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "agent.py"
      ],
      "metadata": {
        "id": "iaz63AIIt_cs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_66r_N10YJVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b6e712-6a27-4da7-9d3a-ea1fbd14c428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to your AI Assistant. Type 'goodbye' to quit.\n",
            "\n",
            "You: goodbye\n",
            "\n",
            "AI Assistant: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"GEMINI_API_KEY not found. Please add it in Colab Secrets.\")\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "print(\"Welcome to your AI Assistant. Type 'goodbye' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    prompt = input(\"You: \")\n",
        "    if prompt.lower() == \"goodbye\":\n",
        "        print(\"\\nAI Assistant: Goodbye!\")\n",
        "        break\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    print(\"AI Assistant:\", response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "client.py for stdio transport"
      ],
      "metadata": {
        "id": "GtH6ap0buHgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "from contextlib import AsyncExitStack\n",
        "from mcp import ClientSession\n",
        "from mcp.client.stdio import StdioServerParameters, stdio_client\n",
        "\n",
        "class MCPClient:\n",
        "    \"\"\"MCP Client class for connecting to and interacting with MCP servers.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 command: str,\n",
        "                 server_args: list[str],\n",
        "                 env_vars: dict[str, str] = None,\n",
        "                 ) -> None:\n",
        "        \"\"\"Initialize the MCPClient.\"\"\"\n",
        "        self.name = name\n",
        "        self.command = command\n",
        "        self.server_args = server_args\n",
        "        self.env_vars = env_vars\n",
        "        self._session: ClientSession = None\n",
        "        self._exit_stack: AsyncExitStack = AsyncExitStack()\n",
        "        self._connected: bool = False\n",
        "\n",
        "    async def connect(self) -> None:\n",
        "        \"\"\"Connect to the server set in the constructor.\"\"\"\n",
        "        if self.connected:\n",
        "          raise RuntimeError(\"Client is already connected\")\n",
        "\n",
        "        server_parameters = StdioServerParameters(\n",
        "            command=self.command,\n",
        "            args=self.server_args,\n",
        "            env=self.env_vars if self.env_vars else None\n",
        "        )\n",
        "\n",
        "        # Connect to stdio server, starting subprocess\n",
        "        stdio_connection = await self._exit_stack.enter_async_context(\n",
        "            stdio_client(server_parameters)\n",
        "        )\n",
        "        self.read, self.write = stdio_connection\n",
        "\n",
        "        # Start MCP client session\n",
        "        self.session = await self._exit_stack.enter_async_context(\n",
        "            ClientSession(read_stream=self.read, write_stream=self.write)\n",
        "        )\n",
        "\n",
        "        # Initialize session\n",
        "        await self._session.initialize()\n",
        "        self._connected = True\n",
        "\n",
        "    async def get_available_tools(self) -> list[Any]:\n",
        "        \"\"\"Retrieve tools that the server has made available.\"\"\"\n",
        "        pass\n",
        "\n",
        "    async def use_tool(self, tool_name: str, tool_args: list | None = None):\n",
        "        \"\"\"Given a tool name and optionally a list of argumnents, execute the tool.\"\"\"\n",
        "        pass\n",
        "\n",
        "    async def disconnect(self) -> None:\n",
        "        \"\"\"Clean up any resources.\"\"\"\n",
        "        if self._exit_stack:\n",
        "          await self._exit_stack.aclose()\n",
        "          self._connected = False\n",
        "          self._session = None"
      ],
      "metadata": {
        "id": "d_WT1AZquFkq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "client.py for streamable http transport"
      ],
      "metadata": {
        "id": "zGF7O81FK0D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import AsyncExitStack\n",
        "from typing import Callable\n",
        "from mcp import ClientSession\n",
        "from mcp.client.streamable_http import streamablehttp_client\n",
        "\n",
        "class MCPClient:\n",
        "    def __init__(self, name: str, server_url: str) -> None:\n",
        "        self.name = name\n",
        "        self.server_url = server_url\n",
        "        self._session: ClientSession = None\n",
        "        self._exit_stack = AsyncExitStack()\n",
        "        self._connected: bool = False\n",
        "        self._get_session_id: Callable[[], str] = None\n",
        "\n",
        "    async def connect(self, headers: dict | None = None) -> None:\n",
        "        if self.connected:\n",
        "          raise RuntimeError(\"Client is already connected\")\n",
        "\n",
        "        # Connect to Streamable HTTP server\n",
        "        streamable_connection = await self._exit_stack.enter_async_context(streamablehttp_client(url=self.server_url, headers=headers))\n",
        "        self.read, self.write, self._get_session_id = streamable_connection\n",
        "\n",
        "        # Start MCP client session\n",
        "        self._session = await self._exit_stack.enter_async_context(ClientSession(read_stream=self.read, write_stream=self.write))\n",
        "\n",
        "        # Intialize session\n",
        "        await self._session.initialize()\n",
        "        self._connected = True\n",
        "\n",
        "    async def disconnect(self) -> None:\n",
        "        \"\"\"Clean up any resources.\"\"\"\n",
        "        if self._exit_stack:\n",
        "          await self._exit_stack.aclose()\n",
        "          self._connected = False\n",
        "          self._session = None\n",
        ""
      ],
      "metadata": {
        "id": "rLAvqS8bK5Rx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "instantiate stdio client: updated agent.py"
      ],
      "metadata": {
        "id": "jdk4Mr5MPFX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from pathlib import Path\n",
        "\n",
        "import google.generativeai as genai\n",
        "from client import MCPClient\n",
        "\n",
        "\n",
        "API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"GEMINI_API_KEY not found. Please add it in Colab Secrets.\")\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "mcp_client = MCPClient(\n",
        "    name=\"calculator_server_connection\",\n",
        "    command=\"uv\",\n",
        "    server_args=[\n",
        "        \"--directory\",\n",
        "        str(Path(__file__).parent.parent.resolve()),\n",
        "        \"run\",\n",
        "        \"calculator_server.py\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"Welcome to your AI Assistant. Type 'goodbye' to quit.\\n\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"Main async function to run the assistant.\"\"\"\n",
        "    await mcp_client.connect()\n",
        "    available_tools = await mcp_client.get_available_tools()\n",
        "    print(\n",
        "        f\"Available tools: {', '.join([tool['name'] for tool in available_tools])}\"\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        prompt = input(\"You: \")\n",
        "        if prompt.lower() == \"goodbye\":\n",
        "            print(\"AI Assistant: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = model.generate_content(prompt)\n",
        "        print(f\"Assistant: {response.text}\")\n",
        "\n",
        "    await mcp_client.disconnect()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "i4LOoog6PJCW",
        "outputId": "97e8af43-6973-4436-b66c-c017c85710e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'client'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3496718431.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerativeai\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMCPClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'client'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}